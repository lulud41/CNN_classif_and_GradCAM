{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap (Grad Cam) and Localization\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DEROUET Lucien\n",
    "lucien.derouet@utt.fr\n",
    "\n",
    "> Notebook implémentation du GradCAM pour la localisation des défauts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (99,2792,1)\n",
    "image_shape = (2792,99)\n",
    "\n",
    "output_layer_num = -4\n",
    "\n",
    "WHEEL_PART = \"ajours\"\n",
    "\n",
    "DATA_PATH = \"/home/cogrannr/roues/MEFRO/grises/img_\"+WHEEL_PART+\"_avec_defauts/\"\n",
    "MASK_PATH = \"/home/cogrannr/roues/MEFRO/grises/img_\"+WHEEL_PART+\"_masque_defauts/\"\n",
    "\n",
    "MODEL_RESNET = \"/home/etu/derouetl/mefro_v2/trained_models/wheel_part/gray/resnet_gray_\"+WHEEL_PART+\".h5\"\n",
    "\n",
    "threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defauts réels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam():\n",
    "\n",
    "    def __init__(self, model_name, nb_layers,\n",
    "        input_shape=(99,2792,1), image_shape= (2792,99)):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.input_shape = input_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.nb_layers = nb_layers\n",
    "        self.model = self.init_model(nb_layers, model_name)\n",
    "        self.saved_cam = []\n",
    "        self.file_names_list = []\n",
    "\n",
    "    def load_image(self, name):\n",
    "\n",
    "        image = PIL.Image.open(name)\n",
    "        image = image.resize(image_shape)\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "        image = image[np.newaxis,:,:,np.newaxis]\n",
    "\n",
    "        return image\n",
    "\n",
    "    def load_image_rgb(self, name, noise_factor=7):\n",
    "\n",
    "        image = self.load_image(name)\n",
    "        image = np.repeat(image, 3, axis=3)\n",
    "        #image = image + np.random.randn(image.shape)\n",
    "\n",
    "        image = image + tf.random.normal(image.shape)*noise_factor\n",
    "        image = tf.clip_by_value(image,0,255)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def init_model(self, nb_layers, model_name):\n",
    "\n",
    "        base_model = tf.keras.models.load_model(model_name)\n",
    "        model_output = base_model.layers[nb_layers].output\n",
    "\n",
    "\n",
    "        model = tf.keras.Model(inputs=base_model.input, outputs=[model_output, base_model.output])\n",
    "\n",
    "        print(base_model.summary())\n",
    "        print(\"model output \",base_model.layers[nb_layers])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def heatmap(self, image, image_name, plot_images=False):\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            activation, pred = self.model(image)\n",
    "\n",
    "        if pred == 1:\n",
    "            #print(\"error : 0 gradient\")\n",
    "            return 1\n",
    "        if pred < 0.5:\n",
    "            #print(\" pred : no defect\")\n",
    "            return 1\n",
    "\n",
    "        d = g.gradient(pred, activation)\n",
    "\n",
    "        d = tf.math.reduce_mean(d[0],axis=(0,1))\n",
    "        activation = activation[0]\n",
    "\n",
    "        cam = np.zeros(activation.shape[0:2])\n",
    "\n",
    "        for i in range(0,activation.shape[2]):\n",
    "            cam = cam + d[i]*activation[:,:,i]\n",
    "\n",
    "        cam_relu = tf.math.maximum(cam, 0)\n",
    "        cam_relu = tf.get_static_value(cam_relu)\n",
    "\n",
    "        # appliquer cmap\n",
    "        cam_relu = cv2.resize(cam_relu, (image.shape[2],image.shape[1]))\n",
    "\n",
    "        cam_relu = cam_relu / (np.max(cam_relu)+ 1e-5)\n",
    "\n",
    "        cam = np.uint8(255*cam_relu)\n",
    "\n",
    "        self.saved_cam.append(cam)\n",
    "        self.file_names_list.append(image_name)\n",
    "\n",
    "        if plot_images == True:\n",
    "            plt.matshow(cam)\n",
    "            plt.show()\n",
    "            input(\"press enter\")\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def heatmap_list_images(self, path, rgb=False, plot_images=False):\n",
    "\n",
    "        for f in np.sort(os.listdir(path)):\n",
    "\n",
    "            if rgb == False:\n",
    "                image = self.load_image(path+f)\n",
    "            else:\n",
    "                image = self.load_image_rgb(path+f)\n",
    "\n",
    "            #print(\"current image\", f)\n",
    "            self.heatmap(image, f, plot_images=plot_images)\n",
    "\n",
    "    def get_grad_cam(self):\n",
    "        cam = self.saved_cam\n",
    "        cam = np.array([*cam])\n",
    "        self.saved_cam = []\n",
    "        return cam\n",
    "\n",
    "    def get_file_names_list(self):\n",
    "        files = self.file_names_list\n",
    "        self.file_names_list = []\n",
    "        return files\n",
    "\n",
    "    def save_grad_cam(self, name):\n",
    "\n",
    "        computed_cam = np.array([*self.saved_cam])\n",
    "        file_names = np.array(self.file_names_list)\n",
    "\n",
    "        np.savez_compressed(name,grad_cam=computed_cam, file_name=file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Localization_from_heatmap():\n",
    "    def __init__(self, threshold=0.7):\n",
    "        self.heatmaps = []\n",
    "        self.bbox_list = []\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def init_data(self, data_intput):\n",
    "\n",
    "        # just one heatmap (n,m) make it (1,h,w)\n",
    "        if data_intput.ndim == 2:\n",
    "            self.heatmaps = data_intput[nb.newaxis,:,:]\n",
    "\n",
    "        # heatmap (n,h,w)\n",
    "        if data_intput.ndim == 3:\n",
    "            self.heatmaps = data_intput\n",
    "\n",
    "\n",
    "    def init_data_from_file(self, file_name):\n",
    "        data = np.load(file_name)\n",
    "        heatmaps = data[data.files[0]]\n",
    "        file_names = data[data.files[1]]\n",
    "        return heatmaps, file_names\n",
    "\n",
    "    def threshold_heatmaps(self):\n",
    "        for i in range(self.heatmaps.shape[0]):\n",
    "            array = self.heatmaps[i]\n",
    "            array[ array < self.threshold*array.max() ] = 0\n",
    "            array[array != 0] = 255\n",
    "\n",
    "            self.heatmaps[i] = array\n",
    "\n",
    "    def compute_bounding_box(self, data):\n",
    "        self.init_data(data)\n",
    "\n",
    "        self.threshold_heatmaps()\n",
    "\n",
    "        for i in range(self.heatmaps.shape[0]):\n",
    "            contour = cv2.findContours(self.heatmaps[i], cv2.RETR_TREE,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "            if len(contour) > 1:\n",
    "                return 1\n",
    "                \n",
    "            contour = contour[0]\n",
    "\n",
    "            #x,y  : top left coordinate, horizontal axis\n",
    "            # width and height horiz and vertical\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            self.bbox_list.append([x,y,w,h])\n",
    "            \n",
    "            return 0\n",
    "\n",
    "    def get_bounding_box(self):\n",
    "        bbox = self.bbox_list\n",
    "        self.bbox_list = []\n",
    "        self.heatmaps = []\n",
    "        return self.adapt_bbox(bbox)\n",
    "\n",
    "    def adapt_bbox(self, bbox_list):\n",
    "\n",
    "        adapted_bbox = []\n",
    "\n",
    "        for box in bbox_list:\n",
    "\n",
    "            top_left_corner_x = box[1]\n",
    "            top_left_corner_y = box[0]\n",
    "\n",
    "            h = box[3]\n",
    "            w = box[2]\n",
    "\n",
    "            x = top_left_corner_x + h//2\n",
    "            y = top_left_corner_y + w//2\n",
    "\n",
    "            adapted_bbox.append([x,y,h,w])\n",
    "\n",
    "        return np.array(adapted_bbox)\n",
    "\n",
    "    def plot_gray_images_with_bbox(self, image_name_list, image_path, bbox_list, heamap_list, image_shape=(2792,99)):\n",
    "\n",
    "        b = self.adapt_bbox(bbox_list)\n",
    "\n",
    "        for i in range(len(image_name_list)):\n",
    "            print(image_name_list[i])\n",
    "            print(b[i])\n",
    "\n",
    "            image_name = image_name_list[i]\n",
    "\n",
    "            image = PIL.Image.open(image_path+image_name)\n",
    "            image = image.resize(image_shape)\n",
    "            image = np.array(image, dtype=np.uint8)\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.repeat(image, 3, axis=2)\n",
    "\n",
    "            bbox = bbox_list[i]\n",
    "\n",
    "            image = cv2.rectangle(image, (bbox[0], bbox[1]),\n",
    "                (bbox[0]+bbox[2], bbox[1]+bbox[3]), (255,0,0), 3)\n",
    "\n",
    "            #cv2 draw rect puis plot\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(20,2), sharex=True)#,sharex=True, gridspec_kw={'hspace': 10})\n",
    "\n",
    "            axs[0].imshow(image)\n",
    "            axs[1].imshow(heamap_list[i])\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            input(\"next image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bbox_from_mask(list_files, path_mask=\"\", image_shape=(2792,99)):\n",
    "    bbox_mask = []\n",
    "    i=0\n",
    "    for file in list_files:\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        file = file[0]\n",
    "        image = PIL.Image.open(path_mask+file[:-3]+\"png\")\n",
    "        image = np.array(image.resize(image_shape))\n",
    "\n",
    "        indexes = np.where(image == 255)\n",
    "\n",
    "        top_left_corner = [ indexes[0][0], indexes[1][0] ]\n",
    "\n",
    "        bottom_right_corner = [ indexes[0][-1], indexes[1][-1] ]\n",
    "        # horizontald length\n",
    "        bbox_w  = bottom_right_corner[1] - top_left_corner[1] +1\n",
    "        # vertical length\n",
    "        bbox_h = bottom_right_corner[0] - top_left_corner[0] +1\n",
    "        # center x coordinate\n",
    "        bbox_x = top_left_corner[0] + bbox_h//2\n",
    "        # center y coordinate\n",
    "        bbox_y = top_left_corner[1] + bbox_w//2\n",
    "\n",
    "        bbox_mask.append(np.array([bbox_x, bbox_y, bbox_h, bbox_w]))\n",
    "        i=i+1\n",
    "\n",
    "    return np.array([*bbox_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(predicted_bbox, ground_truth_bbox):\n",
    "\n",
    "    pred_x1 = predicted_bbox[:,0] - predicted_bbox[:,2]//2\n",
    "    pred_x2 = predicted_bbox[:,0] + predicted_bbox[:,2]//2\n",
    "    pred_y1 = predicted_bbox[:,1] - predicted_bbox[:,3]//2\n",
    "    pred_y2 = predicted_bbox[:,1] + predicted_bbox[:,3]//2\n",
    "\n",
    "    truth_x1 = ground_truth_bbox[:,0] - ground_truth_bbox[:,2]//2\n",
    "    truth_x2 = ground_truth_bbox[:,0] + ground_truth_bbox[:,2]//2\n",
    "    truth_y1 = ground_truth_bbox[:,1] - ground_truth_bbox[:,3]//2\n",
    "    truth_y2 = ground_truth_bbox[:,1] + ground_truth_bbox[:,3]//2\n",
    "\n",
    "    I_x1 = np.maximum(pred_x1, truth_x1)\n",
    "    I_y1 = np.maximum(pred_y1, truth_y1)\n",
    "\n",
    "    I_x2 = np.minimum(pred_x2, truth_x2)\n",
    "    I_y2 = np.minimum(pred_y2, truth_y2)\n",
    "\n",
    "    intersection = np.maximum((I_x2 - I_x1 + 1),0)*np.maximum((I_y2 - I_y1 +1),0)\n",
    "\n",
    "    IoU = intersection / ( (truth_y2 - truth_y1+1)*(truth_x2 - truth_x1+1) +\n",
    "            (pred_x2 - pred_x1+1)*(pred_y2 - pred_y1+1) - intersection)\n",
    "\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 99, 2792, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 105, 2798, 3) 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 1396, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 1398, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 698, 64)  0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 25, 698, 64)  256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 25, 698, 64)  0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 698, 64)  4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 698, 64)  256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 698, 64)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 27, 700, 64)  0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 698, 64)  36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 698, 64)  256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 698, 64)  0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 698, 256) 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 698, 256) 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 25, 698, 256) 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 25, 698, 256) 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 25, 698, 256) 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 698, 64)  16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 698, 64)  256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 698, 64)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 27, 700, 64)  0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 698, 64)  36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 698, 64)  256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 698, 64)  0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 698, 256) 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 25, 698, 256) 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 25, 698, 256) 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 25, 698, 256) 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 698, 64)  16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 698, 64)  256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 698, 64)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 27, 700, 64)  0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 13, 349, 64)  36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 13, 349, 64)  256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 13, 349, 64)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 13, 349, 256) 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 13, 349, 256) 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 13, 349, 256) 0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 13, 349, 256) 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 13, 349, 256) 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 349, 128) 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 349, 128) 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 15, 351, 128) 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 349, 128) 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 349, 128) 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 349, 512) 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 349, 512) 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 13, 349, 512) 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 13, 349, 512) 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 13, 349, 512) 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 349, 128) 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 349, 128) 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 15, 351, 128) 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 349, 128) 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 349, 128) 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 349, 512) 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 13, 349, 512) 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 13, 349, 512) 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 13, 349, 512) 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 349, 128) 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 349, 128) 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 15, 351, 128) 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 349, 128) 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 349, 128) 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 349, 512) 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 13, 349, 512) 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 13, 349, 512) 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 13, 349, 512) 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 349, 128) 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 349, 128) 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 349, 128) 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 15, 351, 128) 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 7, 175, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 7, 175, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 7, 175, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 175, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 7, 175, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 7, 175, 512)  0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 7, 175, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 7, 175, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 175, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 175, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 175, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 175, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 175, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 175, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 7, 175, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 7, 175, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 7, 175, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 175, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 175, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 175, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 175, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 175, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 7, 175, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 7, 175, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 7, 175, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 175, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 175, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 175, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 175, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 175, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 7, 175, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 7, 175, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 7, 175, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 175, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 175, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 175, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 175, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 175, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 7, 175, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 7, 175, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 7, 175, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 175, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 175, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 175, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 175, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 175, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 7, 175, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 7, 175, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 7, 175, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 175, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 175, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 175, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 9, 177, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 88, 256)   589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 88, 256)   1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 4, 88, 256)   0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 88, 1024)  0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 88, 1024)  263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 4, 88, 1024)  0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 4, 88, 1024)  4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 4, 88, 1024)  0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 88, 512)   524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 88, 512)   0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 6, 90, 512)   0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 88, 512)   2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 88, 512)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 88, 2048)  2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 88, 2048)  1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 4, 88, 2048)  0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 4, 88, 2048)  8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 4, 88, 2048)  0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 88, 512)   1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 88, 512)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 6, 90, 512)   0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 88, 512)   2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 88, 512)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 88, 2048)  1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 4, 88, 2048)  0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 4, 88, 2048)  8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 4, 88, 2048)  0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 88, 512)   1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 88, 512)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 6, 90, 512)   0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 88, 512)   2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 88, 512)   2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 88, 512)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 88, 2048)  1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 4, 88, 2048)  0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 4, 88, 2048)  8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 4, 88, 2048)  0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 720896)       0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 720896)       0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            720897      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,285,697\n",
      "Trainable params: 24,240,257\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model output  <tensorflow.python.keras.layers.core.Activation object at 0x7f78c85d5f70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image  0 grad cam :  0\n",
      "image  50 grad cam :  5\n",
      "image  100 grad cam :  11\n",
      "image  150 grad cam :  19\n",
      "image  200 grad cam :  25\n",
      "image  250 grad cam :  31\n",
      "image  300 grad cam :  38\n",
      "image  350 grad cam :  44\n",
      "image  400 grad cam :  50\n",
      "image  450 grad cam :  56\n",
      "image  500 grad cam :  60\n",
      "image  550 grad cam :  62\n",
      "image  600 grad cam :  71\n",
      "image  650 grad cam :  76\n",
      "image  700 grad cam :  80\n",
      "image  750 grad cam :  89\n",
      "image  800 grad cam :  94\n",
      "image  850 grad cam :  104\n",
      "image  900 grad cam :  113\n",
      "image  950 grad cam :  123\n",
      "image  1000 grad cam :  129\n",
      "image  1050 grad cam :  131\n",
      "image  1100 grad cam :  135\n",
      "image  1150 grad cam :  136\n",
      "image  1200 grad cam :  144\n",
      "image  1250 grad cam :  151\n",
      "image  1300 grad cam :  160\n",
      "image  1350 grad cam :  166\n",
      "image  1400 grad cam :  175\n",
      "image  1450 grad cam :  181\n",
      "image  1500 grad cam :  187\n",
      "image  1550 grad cam :  195\n",
      "image  1600 grad cam :  201\n",
      "image  1650 grad cam :  210\n",
      "image  1700 grad cam :  218\n",
      "image  1750 grad cam :  228\n",
      "image  1800 grad cam :  231\n",
      "image  1850 grad cam :  239\n",
      "image  1900 grad cam :  248\n",
      "image  1950 grad cam :  251\n",
      "image  2000 grad cam :  256\n",
      "image  2050 grad cam :  258\n",
      "image  2100 grad cam :  265\n",
      "image  2150 grad cam :  273\n",
      "image  2200 grad cam :  279\n",
      "image  2250 grad cam :  281\n",
      "image  2300 grad cam :  288\n",
      "image  2350 grad cam :  292\n",
      "image  2400 grad cam :  295\n",
      "image  2450 grad cam :  300\n",
      "image  2500 grad cam :  306\n",
      "image  2550 grad cam :  316\n",
      "image  2600 grad cam :  324\n",
      "image  2650 grad cam :  329\n",
      "image  2700 grad cam :  332\n",
      "image  2750 grad cam :  337\n",
      "image  2800 grad cam :  346\n",
      "image  2850 grad cam :  355\n",
      "image  2900 grad cam :  363\n",
      "image  2950 grad cam :  369\n",
      "image  3000 grad cam :  375\n",
      "image  3050 grad cam :  381\n",
      "image  3100 grad cam :  388\n",
      "image  3150 grad cam :  394\n",
      "image  3200 grad cam :  399\n",
      "image  3250 grad cam :  403\n",
      "image  3300 grad cam :  409\n",
      "image  3350 grad cam :  415\n",
      "image  3400 grad cam :  421\n",
      "image  3450 grad cam :  428\n",
      "image  3500 grad cam :  433\n",
      "image  3550 grad cam :  438\n",
      "image  3600 grad cam :  446\n",
      "image  3650 grad cam :  453\n",
      "image  3700 grad cam :  460\n",
      "image  3750 grad cam :  466\n",
      "image  3800 grad cam :  473\n",
      "image  3850 grad cam :  481\n",
      "image  3900 grad cam :  482\n",
      "image  3950 grad cam :  487\n",
      "image  4000 grad cam :  490\n",
      "image  4050 grad cam :  495\n",
      "image  4100 grad cam :  503\n",
      "image  4150 grad cam :  508\n",
      "image  4200 grad cam :  515\n",
      "image  4250 grad cam :  519\n",
      "image  4300 grad cam :  524\n",
      "image  4350 grad cam :  530\n",
      "image  4400 grad cam :  534\n",
      "image  4450 grad cam :  538\n",
      "image  4500 grad cam :  545\n",
      "image  4550 grad cam :  551\n",
      "image  4600 grad cam :  555\n",
      "image  4650 grad cam :  565\n",
      "image  4700 grad cam :  573\n",
      "image  4750 grad cam :  580\n",
      "image  4800 grad cam :  589\n",
      "image  4850 grad cam :  592\n",
      "image  4900 grad cam :  596\n",
      "image  4950 grad cam :  598\n",
      "image  5000 grad cam :  603\n",
      "image  5050 grad cam :  612\n",
      "image  5100 grad cam :  618\n",
      "image  5150 grad cam :  624\n",
      "image  5200 grad cam :  631\n",
      "image  5250 grad cam :  636\n",
      "image  5300 grad cam :  645\n",
      "image  5350 grad cam :  650\n",
      "image  5400 grad cam :  657\n",
      "image  5450 grad cam :  665\n",
      "image  5500 grad cam :  672\n",
      "image  5550 grad cam :  681\n",
      "image  5600 grad cam :  686\n",
      "image  5650 grad cam :  689\n",
      "image  5700 grad cam :  692\n",
      "image  5750 grad cam :  697\n",
      "image  5800 grad cam :  704\n",
      "image  5850 grad cam :  707\n",
      "image  5900 grad cam :  713\n",
      "image  5950 grad cam :  720\n",
      "image  6000 grad cam :  723\n",
      "image  6050 grad cam :  731\n",
      "image  6100 grad cam :  734\n",
      "image  6150 grad cam :  739\n",
      "image  6200 grad cam :  742\n",
      "image  6250 grad cam :  747\n",
      "image  6300 grad cam :  753\n",
      "image  6350 grad cam :  758\n",
      "image  6400 grad cam :  767\n",
      "image  6450 grad cam :  775\n",
      "image  6500 grad cam :  779\n",
      "image  6550 grad cam :  788\n",
      "image  6600 grad cam :  797\n",
      "image  6650 grad cam :  802\n",
      "image  6700 grad cam :  810\n",
      "image  6750 grad cam :  817\n",
      "image  6800 grad cam :  824\n",
      "image  6850 grad cam :  827\n",
      "image  6900 grad cam :  833\n",
      "image  6950 grad cam :  841\n",
      "image  7000 grad cam :  849\n",
      "image  7050 grad cam :  856\n",
      "image  7100 grad cam :  860\n",
      "image  7150 grad cam :  864\n",
      "image  7200 grad cam :  867\n",
      "image  7250 grad cam :  873\n",
      "image  7300 grad cam :  878\n",
      "image  7350 grad cam :  882\n",
      "image  7400 grad cam :  885\n",
      "image  7450 grad cam :  893\n",
      "image  7500 grad cam :  898\n",
      "image  7550 grad cam :  901\n",
      "image  7600 grad cam :  905\n",
      "image  7650 grad cam :  911\n",
      "image  7700 grad cam :  920\n",
      "image  7750 grad cam :  927\n",
      "image  7800 grad cam :  930\n",
      "image  7850 grad cam :  934\n",
      "image  7900 grad cam :  937\n",
      "image  7950 grad cam :  944\n",
      "image  8000 grad cam :  950\n",
      "image  8050 grad cam :  955\n",
      "image  8100 grad cam :  959\n",
      "image  8150 grad cam :  964\n",
      "image  8200 grad cam :  972\n",
      "image  8250 grad cam :  980\n",
      "image  8300 grad cam :  984\n",
      "image  8350 grad cam :  987\n",
      "image  8400 grad cam :  991\n",
      "image  8450 grad cam :  997\n",
      "image  8500 grad cam :  999\n",
      "image  8550 grad cam :  1005\n",
      "image  8600 grad cam :  1011\n",
      "image  8650 grad cam :  1017\n",
      "image  8700 grad cam :  1023\n",
      "image  8750 grad cam :  1029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4242\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4243\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4244\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: Expecting float value for attr exponential_avg_factor, got int",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-649a9669c085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-59028eb33542>\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(self, image, image_name, plot_images)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m     output, mean, variance = tf_utils.smart_cond(training, train_op,\n\u001b[0m\u001b[1;32m    604\u001b[0m                                                  _fused_batch_norm_inference)\n\u001b[1;32m    605\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     return control_flow_ops.cond(\n\u001b[1;32m     63\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m---> 64\u001b[0;31m   return smart_module.smart_cond(\n\u001b[0m\u001b[1;32m     65\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       return nn.fused_batch_norm(\n\u001b[0m\u001b[1;32m    586\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m           \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     y, running_mean, running_var, _, _, _ = gen_nn_ops.fused_batch_norm_v3(\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4250\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4251\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4252\u001b[0;31m         return fused_batch_norm_v3_eager_fallback(\n\u001b[0m\u001b[1;32m   4253\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4254\u001b[0m             \u001b[0mexponential_avg_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexponential_avg_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3_eager_fallback\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name, ctx)\u001b[0m\n\u001b[1;32m   4314\u001b[0m   \u001b[0;34m\"exponential_avg_factor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexponential_avg_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4315\u001b[0m   data_format, \"is_training\", is_training)\n\u001b[0;32m-> 4316\u001b[0;31m   _result = _execute.execute(b\"FusedBatchNormV3\", 6, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m   4317\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m   4318\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compute 1000 bbox\n",
    "\n",
    "grad_cam_tool = GradCam(MODEL_RESNET, output_layer_num)\n",
    "localization_tool = Localization_from_heatmap()\n",
    "\n",
    "image_names = os.listdir(DATA_PATH)\n",
    "\n",
    "i=0\n",
    "\n",
    "grad_cam_file_name_list = []\n",
    "\n",
    "while len(localization_tool.bbox_list) != 2000:\n",
    "    \n",
    "    if i%50==0:\n",
    "        print(\"image \",i, \"grad cam : \",len(localization_tool.bbox_list))\n",
    "    \n",
    "    image = grad_cam_tool.load_image_rgb(DATA_PATH+image_names[i])\n",
    "\n",
    "    result = grad_cam_tool.heatmap(image,image_names[i])\n",
    "\n",
    "    if result == 0:\n",
    "        grad_cam = grad_cam_tool.get_grad_cam()\n",
    "        \n",
    "        r = localization_tool.compute_bounding_box(grad_cam)\n",
    "    \n",
    "        if r == 0:\n",
    "            grad_cam_file_name = grad_cam_tool.get_file_names_list()\n",
    "            grad_cam_file_name_list.append(grad_cam_file_name)\n",
    "            \n",
    "    i=i+1\n",
    "\n",
    "bbox_arr = localization_tool.get_bounding_box()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-a5bb989189bd>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  file_names=np.array(grad_cam_file_name_list), bbox_mask=bbox_mask)\n"
     ]
    }
   ],
   "source": [
    "bbox_mask=generate_bbox_from_mask(grad_cam_file_name_list,MASK_PATH)\n",
    "\n",
    "np.savez_compressed(\"localization_pred_and_mask_ajours_2\",bbox_pred=bbox_arr,\n",
    "                    file_names=np.array(grad_cam_file_name_list), bbox_mask=bbox_mask)\n",
    "\n",
    "IoU=compute_IoU(bbox_arr, bbox_mask)\n",
    "np.savez_compressed(\"IoU_ajours_2\",IoU=IoU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_venv",
   "language": "python",
   "name": "deep_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
