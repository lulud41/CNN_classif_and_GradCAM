{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DEROUET Lucien\n",
    "lucien.derouet@utt.fr\n",
    "\n",
    "Modèle complet : train avec toutes les données de toutes les parties de roues : \n",
    "     > ajours / galbe / central / crochet \n",
    "     > train successif de tous les modèles : images gray, residus, roues entières\n",
    "     > puis test\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMAGE_SIZE = (2792,99)  # Images resize en taille ~ moyenne : moyenne pondérée\n",
    "INPUT_IMAGE_SHAPE = (99,2792,1) # shape qui rentre dans le cnn\n",
    "# même taille pour toutes les parties d'images, présentes en même densité\n",
    "\n",
    "THRESHOLD_PREDICTION = 0.5\n",
    "\n",
    "NUM_CALLS = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "DATA_PATH = \"/home/cogrannr/roues/MEFRO/grises/\"\n",
    "DATA_PATH_DEFAUTS_REELS = \"/home/cogrannr/roues/MEFRO/images_defauts/\"\n",
    "DATA_PATH_ROUES_ENTIERES=\"/home/cogrannr/roues/MEFRO/Images_Roues/Actuelle/gris_blanc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Fonction custom, car doit être fait en eager execution, sinon c'est un param \"none\" passé à Image.open\n",
    "    ouvereture des photos / resize\n",
    "\"\"\"\n",
    "def open_image(file_name): \n",
    "    name = tf.get_static_value(file_name)\n",
    "    name = name.decode()\n",
    "    \n",
    "    image = PIL.Image.open(name)\n",
    "    \n",
    "    image = image.resize(IMAGE_SIZE)\n",
    "    image_arr = np.array(image)\n",
    "    \n",
    "    image_arr = image_arr[:,:,np.newaxis]\n",
    "    return image_arr\n",
    "\n",
    "def open_image_entiere(file_name): \n",
    "    name = tf.get_static_value(file_name)\n",
    "    name = name.decode()\n",
    "    \n",
    "    image = PIL.Image.open(name)\n",
    "    \n",
    "    image = image.resize(IMAGE_SIZE)\n",
    "    image_arr = np.array(image)\n",
    "    return image_arr\n",
    "    \n",
    "def parse_images(filename,label): # appel \"open_image\"\n",
    "    image_arr = tf.py_function(open_image,[filename],tf.float32)\n",
    "    image_arr = tf.image.convert_image_dtype(image_arr,tf.float32)\n",
    "    return image_arr,label\n",
    "\n",
    "def parse_images_entieres(filename,label): # appel \"open_image\"\n",
    "    image_arr = tf.py_function(open_image_entiere,[filename],tf.float32)\n",
    "    image_arr = tf.image.convert_image_dtype(image_arr,tf.float32)\n",
    "    return image_arr,label\n",
    "\n",
    "def data_augmentation(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.random_brightness(image, max_delta=10.0/255.0)\n",
    "    #image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image,label\n",
    "    \n",
    "def reset_shapes_gray(image,label):\n",
    "    image.set_shape(list(INPUT_IMAGE_SHAPE))\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    chargement des listes de fichiers photo\n",
    "\"\"\"\n",
    "def load_data(cover_dir,faulty_dir): \n",
    "    \n",
    "    file_names_cover = tf.data.Dataset.list_files(cover_dir+\"/*\",shuffle=False)\n",
    "    file_names_cover = file_names_cover.take(DATA_SIZE//2)\n",
    "    labels_0 = tf.data.Dataset.from_tensors(0).repeat()\n",
    "    data_set_cover = tf.data.Dataset.zip((file_names_cover,labels_0))\n",
    "    \n",
    "    file_names_faulty = tf.data.Dataset.list_files(faulty_dir+\"/*\",shuffle=False)\n",
    "    file_names_faulty = file_names_faulty.take(DATA_SIZE//2)\n",
    "    labels_1 = tf.data.Dataset.from_tensors(1).repeat()\n",
    "    data_set_faulty = tf.data.Dataset.zip((file_names_faulty,labels_1))\n",
    "   \n",
    "    data_set = data_set_cover.concatenate(data_set_faulty)\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    data_set = data_set.shuffle(DATA_SIZE)\n",
    "   \n",
    "    return data_set\n",
    "\n",
    "def load_data_entieres(cover_dir,faulty_dir, num_negative, num_positive): \n",
    "    \n",
    "    file_names_cover = tf.data.Dataset.list_files(cover_dir,shuffle=False)\n",
    "    labels_0 = tf.data.Dataset.from_tensors(0).repeat()\n",
    "    \n",
    "    data_set_cover = tf.data.Dataset.zip((file_names_cover,labels_0))\n",
    "    data_set_cover = data_set_cover.take(num_negative)\n",
    "    \n",
    "    \n",
    "    file_names_faulty = tf.data.Dataset.list_files(faulty_dir,shuffle=False)\n",
    "    labels_1 = tf.data.Dataset.from_tensors(1).repeat()\n",
    "    \n",
    "    data_set_faulty = tf.data.Dataset.zip((file_names_faulty,labels_1))\n",
    "    data_set_faulty = data_set_faulty.take(num_positive)\n",
    "    \n",
    "    data_set = data_set_cover.concatenate(data_set_faulty)\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    data_set = data_set.shuffle(DATA_SIZE)\n",
    "   \n",
    "    return data_set\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    répartition des fichiers enn ensembles train/valid\n",
    "\"\"\"\n",
    "def generate_train_valid_test(cover_dir,faulty_dir, augment_data=False, entieres=False,\n",
    "                             num_positive=0,num_negative=0): \n",
    "    \n",
    "    if entieres==True:\n",
    "        data_set = load_data_entieres(cover_dir, faulty_dir, num_negative,num_positive)\n",
    "    else:\n",
    "        data_set = load_data(cover_dir, faulty_dir)\n",
    "        \n",
    "    train_dataset = data_set.take(DATA_TRAIN_SIZE)\n",
    "    valid_dataset = data_set.skip(DATA_TRAIN_SIZE).take(DATA_VALID_SIZE)\n",
    "    test_dataset = data_set.skip(DATA_TRAIN_SIZE+DATA_VALID_SIZE).take(DATA_TEST_SIZE)\n",
    "\n",
    "    \n",
    "    datasets_list = []\n",
    "    \n",
    "    for data_set in [train_dataset, valid_dataset, test_dataset]:\n",
    "\n",
    "        if data_set == train_dataset:\n",
    "            if entieres == True:\n",
    "                data_set = data_set.map(parse_images_entieres, num_parallel_calls=NUM_CALLS)\n",
    "            else:\n",
    "                data_set = data_set.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "            if augment_data == True:\n",
    "                data_set = data_set.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "                data_set = data_set.map(data_augmentation, num_parallel_calls=NUM_CALLS)\n",
    "        else:\n",
    "            if entieres == True:\n",
    "                data_set = data_set.map(parse_images_entieres, num_parallel_calls=NUM_CALLS)\n",
    "            else:\n",
    "                data_set = data_set.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "            \n",
    "        data_set = data_set.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "            \n",
    "        data_set = data_set.batch(BATCH_SIZE)\n",
    "        data_set = data_set.prefetch(1)\n",
    "        \n",
    "        datasets_list.append(data_set)\n",
    "        \n",
    "    return datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix : \n",
    "\n",
    "def confusion_matrix(test_dataset,model, num_positive_class, num_negative_class):\n",
    "    \n",
    "    prediction = np.array([])\n",
    "    labels = tf.constant([], dtype=tf.int32)\n",
    "\n",
    "    for (data_batch, label_batch) in test_dataset:\n",
    "        prediction = np.concatenate((prediction, model.predict_on_batch(data_batch)[:,0]))\n",
    "        labels = tf.concat((labels, label_batch), axis=0)\n",
    "  \n",
    "    prediction[prediction > THRESHOLD_PREDICTION] = 1\n",
    "    prediction[prediction <= THRESHOLD_PREDICTION] = 0\n",
    "        \n",
    "    confusion_matrix = tf.math.confusion_matrix(\n",
    "        labels=labels,predictions=tf.convert_to_tensor(prediction),num_classes=2)\n",
    "\n",
    "    l = tf.get_static_value(labels)\n",
    "    \n",
    "    num_pos = np.sum(l==1)\n",
    "    num_neg = np.sum(l==0)\n",
    "    print(\"num pos \",num_pos)\n",
    "    print(\"num neg \",num_neg)\n",
    "    \n",
    "    nomralized_matrix = tf.get_static_value(confusion_matrix)\n",
    "    nomralized_matrix = nomralized_matrix.astype(np.float32)\n",
    "    \n",
    "    nomralized_matrix[0,:] = nomralized_matrix[0,:]/num_neg\n",
    "    nomralized_matrix[1,:] = nomralized_matrix[1,:]/num_pos\n",
    "\n",
    "    print(\"\\nConfusion matrix : \")\n",
    "    print(tf.get_static_value(confusion_matrix))\n",
    "    print(\"\\nNormalized confusion matrix : \")\n",
    "    print(nomralized_matrix)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(architecture=1):\n",
    "    \n",
    "    if architecture == 1:    # 1M param : MARCHE OK\n",
    "        model_input = tf.keras.Input(shape=INPUT_IMAGE_SHAPE)\n",
    "        conv_1 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,2))(model_input)\n",
    "        conv_2 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_1)\n",
    "        bn_1 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "        mxp_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_1)\n",
    "        \n",
    "        conv_3 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,2))(mxp_1)\n",
    "        conv_4 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_3)\n",
    "        bn_2 = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "        mxp_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_2)\n",
    "        \n",
    "        conv_5 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,2))(mxp_2)\n",
    "        conv_6 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_5)\n",
    "        bn_3 = tf.keras.layers.BatchNormalization()(conv_6)\n",
    "        mxp_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_3)\n",
    "        \n",
    "        conv_7 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='SAME',strides=(1,2))(mxp_3)\n",
    "        conv_8 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_7)\n",
    "        bn_4 = tf.keras.layers.BatchNormalization()(conv_8)\n",
    "        mxp_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_4)\n",
    "        \n",
    "        flat = tf.keras.layers.Flatten()(mxp_4)\n",
    "        drop = tf.keras.layers.Dropout(0.3)(flat)\n",
    "        out = tf.keras.layers.Dense(1,activation=\"sigmoid\")(drop)\n",
    "    \n",
    "    if architecture == 2:   # 300 K parametres\n",
    "        model_input = tf.keras.Input(shape=INPUT_IMAGE_SHAPE)\n",
    "        conv_1 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,2))(model_input)\n",
    "        conv_2 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,2))(conv_1)\n",
    "        bn_1 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "        \n",
    "        mxp_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_1)\n",
    "        conv_3 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,2))(mxp_1)\n",
    "        conv_4 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,2))(conv_3)\n",
    "        bn_2 = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "        \n",
    "        mxp_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_2)\n",
    "        conv_5 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,2))(mxp_2)\n",
    "        conv_6 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,2))(conv_5)\n",
    "        #conv_7 = tf.keras.layers.Conv2D(64,(1,1),activation=\"relu\")(conv_6)\n",
    "        \n",
    "        flat = tf.keras.layers.Flatten()(conv_6)\n",
    "        drop_1  = tf.keras.layers.Dropout(rate = 0.3)(flat)\n",
    "        out = tf.keras.layers.Dense(1,activation=\"sigmoid\")(drop_1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=model_input, outputs=out)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dataset,valid_dataset, check_point_name, num_epochs,tensor_board_name=\"\"):\n",
    "    \n",
    "    precision_metric = tf.keras.metrics.Precision(thresholds=THRESHOLD_PREDICTION)\n",
    "    \n",
    "    call_backs_list = [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience = 2),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath =check_point_name, monitor =\"val_accuracy\", save_best_only = True),\n",
    "    ]\n",
    "    \n",
    "    if tensor_board_name != \"\":\n",
    "        board = tf.keras.callbacks.TensorBoard(log_dir='./tensor_board_'+tensor_board_name)\n",
    "        call_backs_list.append(board)\n",
    "   \n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "  \n",
    "    model.compile(loss='binary_crossentropy',optimizer=optim,\n",
    "        metrics=[precision_metric,\"accuracy\"]) \n",
    "    \n",
    "    model.fit(train_dataset,epochs=num_epochs,\n",
    "              validation_data=valid_dataset,\n",
    "             callbacks=call_backs_list\n",
    "             )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Images gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = int(15e3) # taille des données (test/valid/test compris), max : 146K\n",
    "DATA_TRAIN_SIZE = int(DATA_SIZE*0.6)\n",
    "DATA_VALID_SIZE = int(DATA_SIZE*0.2)\n",
    "DATA_TEST_SIZE = int(DATA_SIZE*0.2)\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "\n",
    "NUM_EPOCHS = {\"galbe\":10, \"ajours\":10, \"crochet\":10, \"central\":150}\n",
    "\n",
    "SAVE_PATH = \"./trained_models/wheel_part/gray/\"\n",
    "\n",
    "NUM_POSITIVE_CLASS = DATA_TEST_SIZE//2\n",
    "NUM_NEGATIVE_CLASS = DATA_TEST_SIZE//2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "MODEL_NAME = \"model_v4_gray_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 99, 2792, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 99, 1396, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 99, 1396, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 99, 1396, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 698, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 49, 349, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 49, 349, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 49, 349, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 174, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 87, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 87, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 87, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 11, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16896)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16896)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 16897     \n",
      "=================================================================\n",
      "Total params: 1,190,497\n",
      "Trainable params: 1,189,537\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 7s 177ms/step - accuracy: 0.5100 - loss: 1.1440 - precision: 0.5032 - val_accuracy: 0.4950 - val_loss: 0.6980 - val_precision: 0.4950\n",
      "Epoch 2/10\n",
      "37/38 [============================>.] - ETA: 0s - accuracy: 0.5726 - loss: 0.8041 - precision: 0.5645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7634dbe9738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         model = train_model(model, train_dataset, valid_dataset,\n\u001b[0m\u001b[1;32m     11\u001b[0m                         check_point_name=SAVE_PATH+MODEL_NAME+wheel_part+\".h5\", num_epochs=NUM_EPOCHS[wheel_part])\n",
      "\u001b[0;32m<ipython-input-7-606f92d5de5a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, valid_dataset, check_point_name, num_epochs, tensor_board_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m         metrics=[precision_metric,\"accuracy\"]) \n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     model.fit(train_dataset,epochs=num_epochs,\n\u001b[0m\u001b[1;32m     21\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_backs_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/derouet_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    for wheel_part in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "        train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "\n",
    "        model = init_model(architecture=1)\n",
    "        model = train_model(model, train_dataset, valid_dataset,\n",
    "                        check_point_name=SAVE_PATH+MODEL_NAME+wheel_part+\".h5\", num_epochs=NUM_EPOCHS[wheel_part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating resnet model for wheel part : galbe\n"
     ]
    }
   ],
   "source": [
    "# pour la RAM : bien shutdown le notebook avant cette partie !\n",
    "\n",
    "for wheel_part in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "    \n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+wheel_part+\".h5\")\n",
    "    \n",
    "    print(\"evaluating resnet model for wheel part : \"+wheel_part)\n",
    "    check_point.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  galbe  loaded\n",
      "evaluate model galbe  on data :  galbe\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.7036 - precision: 0.5053 - accuracy: 0.5053\n",
      "evaluate model galbe  on data :  ajours\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.6933 - precision: 0.5089 - accuracy: 0.5063\n",
      "evaluate model galbe  on data :  crochet\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 0.7142 - precision: 0.5053 - accuracy: 0.5053\n",
      "evaluate model galbe  on data :  central\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.8143 - precision: 0.5053 - accuracy: 0.5053\n",
      "model  ajours  loaded\n",
      "evaluate model ajours  on data :  galbe\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 0.3976 - precision_3: 0.9961 - accuracy: 0.91630s - loss: 0.4030 - precision_3: 0\n",
      "evaluate model ajours  on data :  ajours\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 0.0220 - precision_3: 1.0000 - accuracy: 0.9920\n",
      "evaluate model ajours  on data :  crochet\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 6.2991 - precision_3: 0.6446 - accuracy: 0.7103\n",
      "evaluate model ajours  on data :  central\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 5.5079 - precision_3: 0.5100 - accuracy: 0.5140\n",
      "model  crochet  loaded\n",
      "evaluate model crochet  on data :  galbe\n",
      "750/750 [==============================] - 52s 70ms/step - loss: 0.1817 - precision_4: 0.9977 - accuracy: 0.9340\n",
      "evaluate model crochet  on data :  ajours\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 1.8955 - precision_4: 0.5701 - accuracy: 0.5987\n",
      "evaluate model crochet  on data :  crochet\n",
      "750/750 [==============================] - 52s 70ms/step - loss: 0.1141 - precision_4: 0.9923 - accuracy: 0.9623\n",
      "evaluate model crochet  on data :  central\n",
      "750/750 [==============================] - 52s 70ms/step - loss: 39.1708 - precision_4: 0.5053 - accuracy: 0.5053\n",
      "model  central  loaded\n",
      "evaluate model central  on data :  galbe\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 0.1270 - precision_5: 0.9815 - accuracy: 0.9643\n",
      "evaluate model central  on data :  ajours\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 8.8937 - precision_5: 0.5053 - accuracy: 0.5053\n",
      "evaluate model central  on data :  crochet\n",
      "750/750 [==============================] - 51s 69ms/step - loss: 2.6710 - precision_5: 0.5870 - accuracy: 0.6383\n",
      "evaluate model central  on data :  central\n",
      "750/750 [==============================] - 51s 69ms/step - loss: 0.1589 - precision_5: 0.9709 - accuracy: 0.9473\n"
     ]
    }
   ],
   "source": [
    "for name in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+name+\".h5\")\n",
    "    print(\"model \",name,\" loaded\")\n",
    "    for wheel_part in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "    \n",
    "        train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "        print(\"evaluate model\",name,\" on data : \",wheel_part)\n",
    "        check_point.evaluate(test_dataset, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement residus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = int(5e3) # taille des données (test/valid/test compris), max : 146K\n",
    "DATA_TRAIN_SIZE = int(DATA_SIZE*0.6)\n",
    "DATA_VALID_SIZE = int(DATA_SIZE*0.2)\n",
    "DATA_TEST_SIZE = int(DATA_SIZE*0.2)\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "\n",
    "NUM_EPOCHS = 4\n",
    "\n",
    "SAVE_PATH = \"./trained_models/wheel_part/residus/\"\n",
    "\n",
    "NUM_POSITIVE_CLASS = DATA_TEST_SIZE//2\n",
    "NUM_NEGATIVE_CLASS = DATA_TEST_SIZE//2\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "MODEL_NAME = \"model_v4_residus_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 99, 2792, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 99, 1396, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 99, 1396, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 99, 1396, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 49, 698, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 49, 349, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 49, 349, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 49, 349, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 174, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 87, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 24, 87, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 87, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 11, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16896)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16896)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16897     \n",
      "=================================================================\n",
      "Total params: 1,190,497\n",
      "Trainable params: 1,189,537\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train for 5475 steps, validate for 1825 steps\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "5475/5475 [==============================] - 1165s 213ms/step - loss: 0.2046 - precision_1: 0.9612 - accuracy: 0.9305 - val_loss: 0.2189 - val_precision_1: 0.9996 - val_accuracy: 0.9137 7s - loss: 0.2050 - precision_1: 0.9610 -  - ETA: 5s - - ETA: 1s - loss: 0.2046 - precision_1: 0.9\n",
      "Epoch 2/10\n",
      "5475/5475 [==============================] - 893s 163ms/step - loss: 0.1172 - precision_1: 0.9853 - accuracy: 0.9675 - val_loss: 0.1233 - val_precision_1: 0.9984 - val_accuracy: 0.9567\n",
      "Epoch 3/10\n",
      "5475/5475 [==============================] - 856s 156ms/step - loss: 0.0987 - precision_1: 0.9870 - accuracy: 0.9725 - val_loss: 0.0764 - val_precision_1: 0.9949 - val_accuracy: 0.9773n_1: 0.9870 -  - ETA: 5s - loss: 0.098\n",
      "Epoch 4/10\n",
      "5475/5475 [==============================] - 908s 166ms/step - loss: 0.0853 - precision_1: 0.9883 - accuracy: 0.9769 - val_loss: 0.0979 - val_precision_1: 0.9985 - val_accuracy: 0.9682\n",
      "Epoch 5/10\n",
      "1720/5475 [========>.....................] - ETA: 9:40 - loss: 0.0765 - precision_1: 0.9898 - accuracy: 0.9794 - ETA: 34:41 - loss: 0.0913 - precision_1: 0.9 - ETA: 32:04 - loss: 0.0922 - precision_1: 0.9864 - accu - ETA: 26:30 - loss: 0.0816 - precision_1: 0.9880 - ETA: 25:25 - loss: 0.0794 - precision_1: 0.9887 - a - ETA: 24:54 - loss: 0.0815 - precision_1: 0.98 - ETA: - ETA: 21:29 - loss: 0.0768 - precision_1: 0.9886 - accura - ETA: 21:15 - loss: 0.0759 - pr - - ETA: 18:48 - loss: 0.0762 - precision_1: 0.9892 - accur - ETA: 18:46 - loss:  - ETA: 9:44 - loss: 0.076"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    for wheel_part in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "        train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part+\"_residus\", DATA_PATH+\"img_\"+wheel_part+\"_residus_defauts\")\n",
    "\n",
    "        model = init_model(architecture=1)\n",
    "        model = train_model(model, train_dataset, valid_dataset,\n",
    "                check_point_name=SAVE_PATH+MODEL_NAME+wheel_part+\".h5\", num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating resnet model for wheel part : galbe\n",
      "1825/1825 [==============================] - 88s 48ms/step - loss: 0.0474 - precision_1: 0.9921 - accuracy: 0.9876\n",
      "num pos  14540\n",
      "num neg  14660\n",
      "\n",
      "Confusion matrix : \n",
      "[[14550   110]\n",
      " [  245 14295]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9924966  0.00750341]\n",
      " [0.01685007 0.98314995]]\n",
      "evaluating resnet model for wheel part : ajours\n",
      "1825/1825 [==============================] - 90s 50ms/step - loss: 0.0822 - precision_2: 0.9899 - accuracy: 0.9785\n",
      "num pos  14540\n",
      "num neg  14660\n",
      "\n",
      "Confusion matrix : \n",
      "[[14532   128]\n",
      " [  474 14066]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.99126875 0.00873124]\n",
      " [0.03259972 0.96740025]]\n",
      "evaluating resnet model for wheel part : crochet\n",
      "1825/1825 [==============================] - 117s 64ms/step - loss: 0.0882 - precision_3: 0.9947 - accuracy: 0.9726\n",
      "num pos  14540\n",
      "num neg  14660\n",
      "\n",
      "Confusion matrix : \n",
      "[[14577    83]\n",
      " [  688 13852]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.99433833 0.00566166]\n",
      " [0.04731774 0.95268226]]\n",
      "evaluating resnet model for wheel part : central\n",
      "1825/1825 [==============================] - 75s 41ms/step - loss: 0.2278 - precision_4: 0.9552 - accuracy: 0.9150\n",
      "num pos  14540\n",
      "num neg  14660\n",
      "\n",
      "Confusion matrix : \n",
      "[[14105   555]\n",
      " [ 1893 12647]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9621419  0.03785812]\n",
      " [0.13019258 0.8698074 ]]\n"
     ]
    }
   ],
   "source": [
    "# pour la RAM : bien shutdown le notebook avant cette partie !\n",
    "\n",
    "for wheel_part in [\"galbe\", \"ajours\", \"crochet\", \"central\"]:\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part+\"_residus\", DATA_PATH+\"img_\"+wheel_part+\"_residus_defauts\")\n",
    "    \n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+wheel_part+\".h5\")\n",
    "    \n",
    "    print(\"evaluating resnet model for wheel part : \"+wheel_part)\n",
    "    \n",
    "    check_point.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test défauts réels images gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for wheel part : galbe\n",
      "66/66 [==============================] - 3s 53ms/step - loss: 0.3961 - precision_2: 0.9947 - accuracy: 0.8540\n",
      "num pos  524\n",
      "num neg  524\n",
      "\n",
      "Confusion matrix : \n",
      "[[522   2]\n",
      " [151 373]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9961832  0.00381679]\n",
      " [0.28816795 0.71183205]]\n",
      "evaluating model for wheel part : ajours\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.8374 - precision_3: 1.0000 - accuracy: 0.7969\n",
      "num pos  96\n",
      "num neg  96\n",
      "\n",
      "Confusion matrix : \n",
      "[[96  0]\n",
      " [39 57]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[1.      0.     ]\n",
      " [0.40625 0.59375]]\n",
      "evaluating model for wheel part : crochet\n",
      "112/112 [==============================] - 7s 66ms/step - loss: 0.3743 - precision_4: 0.9893 - accuracy: 0.8560\n",
      "num pos  896\n",
      "num neg  896\n",
      "\n",
      "Confusion matrix : \n",
      "[[889   7]\n",
      " [251 645]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9921875  0.0078125 ]\n",
      " [0.28013393 0.7198661 ]]\n"
     ]
    }
   ],
   "source": [
    "# liste des sizes de chaque partie de roues\n",
    "DATA_SIZE_TEST = { \"galbe\":1048 , \"ajours\":192 , \"crochet\":1792 , \"central\":None }  \n",
    "\n",
    "SAVE_PATH = \"./trained_models/wheel_part/gray/\"\n",
    "\n",
    "MODEL_NAME = \"model_v4_gray_\"\n",
    "\n",
    "for wheel_part in [\"galbe\", \"ajours\", \"crochet\"]:   #, \"central\"]:\n",
    "    \n",
    "    DATA_SIZE = DATA_SIZE_TEST[wheel_part]\n",
    "    \n",
    "    NUM_POSITIVE_CLASS = DATA_SIZE//2\n",
    "    NUM_NEGATIVE_CLASS = DATA_SIZE//2\n",
    "    \n",
    "    test_dataset = load_data(DATA_PATH+\"img_\"+wheel_part, \n",
    "            DATA_PATH_DEFAUTS_REELS+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "    \n",
    "    test_dataset = test_dataset.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "    test_dataset = test_dataset.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(1)\n",
    "  \n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+wheel_part+\".h5\")\n",
    "    print(\"evaluating model for wheel part : \"+wheel_part)\n",
    "    check_point.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test défauts réels residus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for wheel part : galbe\n",
      "66/66 [==============================] - 4s 54ms/step - loss: 0.2337 - precision_1: 0.9866 - accuracy: 0.9160\n",
      "num pos  524\n",
      "num neg  524\n",
      "\n",
      "Confusion matrix : \n",
      "[[518   6]\n",
      " [ 82 442]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9885496  0.01145038]\n",
      " [0.15648855 0.84351146]]\n",
      "evaluating model for wheel part : ajours\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.3024 - precision_2: 1.0000 - accuracy: 0.8281\n",
      "num pos  96\n",
      "num neg  96\n",
      "\n",
      "Confusion matrix : \n",
      "[[96  0]\n",
      " [33 63]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[1.      0.     ]\n",
      " [0.34375 0.65625]]\n",
      "evaluating model for wheel part : crochet\n",
      "112/112 [==============================] - 7s 58ms/step - loss: 0.1517 - precision_3: 0.9899 - accuracy: 0.9347\n",
      "num pos  896\n",
      "num neg  896\n",
      "\n",
      "Confusion matrix : \n",
      "[[888   8]\n",
      " [109 787]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.9910714  0.00892857]\n",
      " [0.12165178 0.87834823]]\n"
     ]
    }
   ],
   "source": [
    "DATA_SIZE_TEST = { \"galbe\":1048 , \"ajours\":192 , \"crochet\":1792 , \"central\":None }  \n",
    "\n",
    "SAVE_PATH = \"./trained_models/wheel_part/residus/\"\n",
    "\n",
    "MODEL_NAME = \"model_v4_residus_\"\n",
    "\n",
    "for wheel_part in [\"galbe\", \"ajours\", \"crochet\"]:   #, \"central\"]:\n",
    "    \n",
    "    DATA_SIZE = DATA_SIZE_TEST[wheel_part]\n",
    "    \n",
    "    NUM_POSITIVE_CLASS = DATA_SIZE//2\n",
    "    NUM_NEGATIVE_CLASS = DATA_SIZE//2\n",
    "    \n",
    "    test_dataset = load_data(DATA_PATH+\"img_\"+wheel_part+\"_residus\", \n",
    "            DATA_PATH_DEFAUTS_REELS+\"img_\"+wheel_part+\"_residus_defauts\")\n",
    "    \n",
    "    test_dataset = test_dataset.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "    test_dataset = test_dataset.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(1)\n",
    "  \n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+wheel_part+\".h5\")\n",
    "    print(\"evaluating model for wheel part : \"+wheel_part)\n",
    "    check_point.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train roue entiere : (roues direct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 4\n",
    "\n",
    "IMAGE_SIZE = (1624,1234)  # Images resize en taille ~ moyenne : moyenne pondérée\n",
    "INPUT_IMAGE_SHAPE = (1234,1624,3) # shape qui rentre dans le cnn\n",
    "    #roues deja en rgb\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "DATA_SIZE = int(74533) # taille des données (test/valid/test compris), max : 74533;    6845 : rapport 1:4\n",
    "DATA_TRAIN_SIZE = int(DATA_SIZE*0.6)\n",
    "DATA_VALID_SIZE = int(DATA_SIZE*0.2)\n",
    "DATA_TEST_SIZE = int(DATA_SIZE*0.2)\n",
    "\n",
    "#1369 : total de positives\n",
    "\n",
    "NUM_POSITIVE_CLASS_TOTAL = 1369 # constant\n",
    "NUM_NEGATIVE_CLASS_TOTAL = DATA_SIZE - NUM_POSITIVE_CLASS_TOTAL\n",
    "\n",
    "NUM_POSITIVE_CLASS = int(NUM_POSITIVE_CLASS_TOTAL*0.2) #273 constant\n",
    "\n",
    "NUM_NEGATIVE_CLASS = int(NUM_NEGATIVE_CLASS_TOTAL*0.2) # 1095 pour 1:4    ;  pour tout \n",
    "\n",
    "SAVE_PATH = \"./trained_models/whole_wheel/\"\n",
    "MODEL_NAME_1 = \"model_v4_whole_wheel_1_pour_4.h5\"   #\"model_v4_whole_wheel_1_pour_4.h5\"  1:4\n",
    "MODEL_NAME_2 = \"model_v4_whole_wheel_1_pour_70.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1234, 1624, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1234, 812, 32)     896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1234, 812, 32)     9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1234, 812, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 617, 406, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 617, 203, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 617, 203, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 617, 203, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 308, 101, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 308, 51, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 308, 51, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 308, 51, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 154, 25, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 154, 13, 256)      295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 154, 13, 256)      590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 154, 13, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 77, 6, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 118272)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 118272)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 118273    \n",
      "=================================================================\n",
      "Total params: 1,292,449\n",
      "Trainable params: 1,291,489\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Train for 7454 steps, validate for 2485 steps\n",
      "Epoch 1/4\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "2721/7454 [=========>....................] - ETA: 1:08:08 - loss: 0.1772 - precision: 0.7013 - accuracy: 0.9887"
     ]
    }
   ],
   "source": [
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy() \n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "        cover_dir=DATA_PATH_ROUES_ENTIERES+\"*/*OK*\", \n",
    "        faulty_dir=(DATA_PATH_ROUES_ENTIERES+\"*/*DJ*\",DATA_PATH_ROUES_ENTIERES+\"*/*DG*\"),\n",
    "        augment_data=False,entieres=True, \n",
    "        num_positive=NUM_POSITIVE_CLASS_TOTAL, num_negative=NUM_NEGATIVE_CLASS_TOTAL)\n",
    "\n",
    "    model = init_model(architecture=1)\n",
    "    model = train_model(model, train_dataset, valid_dataset,\n",
    "                                  check_point_name=SAVE_PATH+MODEL_NAME_2, num_epochs=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 33s 145ms/step - loss: 0.0774 - precision: 1.0000 - accuracy: 0.9971\n",
      "num pos  264\n",
      "num neg  1105\n",
      "\n",
      "Confusion matrix : \n",
      "[[1105    0]\n",
      " [   5  259]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[1.         0.        ]\n",
      " [0.01893939 0.9810606 ]]\n"
     ]
    }
   ],
   "source": [
    "# test sur defauts fabriqués, modele 1\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "    cover_dir=DATA_PATH_ROUES_ENTIERES+\"*/*OK*\", \n",
    "    faulty_dir=(DATA_PATH_ROUES_ENTIERES+\"*/*DJ*\",DATA_PATH_ROUES_ENTIERES+\"*/*DG*\"),\n",
    "    augment_data=False,entieres=True, num_positive=NUM_POSITIVE_CLASS_TOTAL, num_negative=NUM_NEGATIVE_CLASS_TOTAL)\n",
    "\n",
    "\n",
    "check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME_1)\n",
    "check_point.evaluate(test_dataset, verbose=1)\n",
    "\n",
    "confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 1078s 651ms/step - loss: 0.0605 - precision_1: 0.7908 - accuracy: 0.9942\n",
      "num pos  280\n",
      "num neg  14616\n",
      "\n",
      "Confusion matrix : \n",
      "[[14549    67]\n",
      " [   21   259]]\n",
      "\n",
      "Normalized confusion matrix : \n",
      "[[0.995416   0.00458402]\n",
      " [0.075      0.925     ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# defauts fabriqués, modele 2\n",
    "train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "    cover_dir=DATA_PATH_ROUES_ENTIERES+\"*/*OK*\", \n",
    "    faulty_dir=(DATA_PATH_ROUES_ENTIERES+\"*/*DJ*\",DATA_PATH_ROUES_ENTIERES+\"*/*DG*\"),\n",
    "    augment_data=False,entieres=True, num_positive=NUM_POSITIVE_CLASS_TOTAL, num_negative=NUM_NEGATIVE_CLASS_TOTAL)\n",
    "\n",
    "\n",
    "check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME_2)\n",
    "check_point.evaluate(test_dataset, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_venv",
   "language": "python",
   "name": "deep_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
